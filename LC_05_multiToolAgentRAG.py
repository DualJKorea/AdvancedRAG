import streamlit as st
from langchain.schema import Document
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.agents import Tool, initialize_agent, AgentType
from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun
import io, sys, re, functools

# ---------------- ë²¡í„° ì €ì¥ì†Œ ----------------
def create_faiss_docs(embedding_model):
    documents = [
        Document(page_content="ReactëŠ” ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(UI)ë¥¼ êµ¬ì¶•í•˜ëŠ” JavaScript ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤."),
        Document(page_content="ReactëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰ë˜ë©°, ìƒíƒœ ê´€ë¦¬ì™€ ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ ì„¤ê³„ê°€ í•µì‹¬ì…ë‹ˆë‹¤."),
        Document(page_content="Spring BootëŠ” Java ê¸°ë°˜ì˜ ë°±ì—”ë“œ í”„ë ˆì„ì›Œí¬ë¡œ REST APIì™€ ì„œë²„ ì‚¬ì´ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•ì— ì‚¬ìš©ë©ë‹ˆë‹¤."),
        Document(page_content="Spring BootëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬, ì„œë²„ ìš´ì˜ í™˜ê²½ ì„¤ì •ì´ ìš©ì´í•©ë‹ˆë‹¤."),
        Document(page_content="ReactëŠ” í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì— ìµœì í™”ë˜ì–´ ìˆìœ¼ë©°, Spring BootëŠ” ë°±ì—”ë“œ ê°œë°œì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."),
        Document(page_content="Reactì™€ Spring BootëŠ” ì„œë¡œ ë‹¤ë¥¸ ë ˆì´ì–´ì—ì„œ ë™ì‘í•˜ë©°, í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ í’€ìŠ¤íƒ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."),
    ]
    return FAISS.from_documents(documents, embedding_model)

def strip_ansi(text: str) -> str:
    return re.sub(r'\x1B\[[0-?]*[ -/]*[@-~]', '', text)

# ---------------- RAG ë¡œê¹… ìš© ----------------
def capture_logs(label):
    """ë°ì½”ë ˆì´í„°: stdout ìº¡ì²˜ + í”„ë¡¬í”„íŠ¸/ê²°ê³¼ ë¡œê¹…"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            old_stdout = sys.stdout
            buf = io.StringIO()
            sys.stdout = buf
            try:
                print(f"\n[{label}] called")
                if args: print(f"args: {args}")
                if kwargs: print(f"kwargs: {kwargs}")

                result = func(*args, **kwargs)

                print(f"[{label}] result:\n{result}\n")

                logs = strip_ansi(buf.getvalue())
                st.session_state.logs.append(logs)   
            finally:
                sys.stdout = old_stdout
            return result
        return wrapper
    return decorator

@capture_logs("LLM")
def run_llm(llm_func, prompt):
    return llm_func(prompt)

@capture_logs("Agent Answer")
def answer_with_agent(agent, question):
    return agent.run(f"User question: {question}\nUse tools as needed to answer.")

# ---------------- ìŠ¤íŠ¸ë¦¼ë¦¿  UI ----------------
st.set_page_config(page_title="FAISS + Multi-Tool Agent Demo", layout="wide")

st.markdown("""
<style>
.chat-bubble{padding:.6em 1em;border-radius:1em;max-width:70%;margin:.4em 0;word-wrap:break-word}
.user-bubble{background:#2C3E50;color:white;margin-left:auto;text-align:right}
.assistant-bubble{background:#E0E0E0;color:black;margin-right:auto;text-align:left}
.logs-bubble{background:#1E1E1E;color:#00FF00;padding:.5em;border-radius:.5em;white-space:pre-wrap;margin:.4em 0;}
</style>
""", unsafe_allow_html=True)

with st.sidebar:
    OPENAI_API_KEY = st.text_input("OpenAI API key", type="password")

st.session_state.setdefault("chat", [])
st.session_state.setdefault("agent_ready", False)
st.session_state.setdefault("logs", [])   

st.title("ğŸ’¬ FAISS + Multi-Tool Agent with Logs Demo")

if OPENAI_API_KEY and not st.session_state.agent_ready:
    # LLM & FAISS
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, openai_api_key=OPENAI_API_KEY)
    emb = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vector_db = create_faiss_docs(emb)

    # Tools
    retriever_tool = Tool(
        name="RetrieverTool",
        func=lambda q: "\n".join([d.page_content for d in vector_db.similarity_search(q, k=3)]),
        description="Vector DBì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    )
    search_tool = DuckDuckGoSearchRun()
    tools = [retriever_tool, search_tool]

    # ì—ì´ì „íŠ¸ - ì œë¡œìƒ·
    agent = initialize_agent(
        tools=tools,
        llm=llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True,
        max_iterations=3
    )

    st.session_state.update({
        "llm": llm,
        "vector_db": vector_db,
        "agent": agent,
        "agent_ready": True
    })

    # ì´ˆê¸° ì§ˆë¬¸
    init_question = "Reactì™€ Spring Bootì˜ ì£¼ìš” ì°¨ì´ì ì„ ì•Œë ¤ì¤˜."
    answer = answer_with_agent(agent, init_question)
    st.session_state.chat.extend([
        ("user", init_question),
        ("assistant", answer),
    ])

# ---------------- ì±— UI ----------------
st.markdown("---")
st.subheader("Chat")
for role, msg in st.session_state.chat:
    cls = "user-bubble" if role=="user" else "assistant-bubble"
    st.markdown(f"<div class='chat-bubble {cls}'><b>{role.title()}:</b> {msg}</div>", unsafe_allow_html=True)

# ---------------- ë¡œê·¸ UI ----------------
if st.session_state.logs:
    st.markdown("---")
    st.subheader("Execution Logs")
    full_logs = "\n".join(st.session_state.logs)
    st.markdown(f"<div class='logs-bubble'>{full_logs}</div>", unsafe_allow_html=True)

# ---------------- ì±— ì••ë ¥ ----------------
if st.session_state.get("agent_ready") and (prompt := st.chat_input("Your question")):
    agent = st.session_state.agent
    answer = answer_with_agent(agent, prompt)
    st.session_state.chat.extend([
        ("user", prompt),
        ("assistant", answer),
    ])
    st.experimental_rerun()

st.markdown("---")
st.caption("FAISS + Multi-Tool Agent demo with stdout logs and top-k retrieval.")
